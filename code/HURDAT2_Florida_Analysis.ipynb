{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdf7e29d",
   "metadata": {},
   "source": [
    "# HURDAT2 Analysis: Storms Near Florida (2004-2025)\n",
    "\n",
    "This notebook downloads and analyzes hurricane data from the HURDAT2 database, focusing on storms that came within 60 nautical miles of Florida from 2004 to 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5c2e4",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Configure Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3981ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, box\n",
    "from shapely import wkt\n",
    "import urllib.request\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "BASE_PATH = Path.cwd().parent if 'code' in Path.cwd().name else Path.cwd()\n",
    "DATA_RAW = BASE_PATH / \"data\" / \"raw\"\n",
    "DATA_PROCESSED = BASE_PATH / \"data\" / \"processed\"\n",
    "DATA_FINAL = BASE_PATH / \"data\" / \"final\"\n",
    "\n",
    "# Ensure directories exist\n",
    "for path in [DATA_RAW, DATA_PROCESSED, DATA_FINAL]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Base path: {BASE_PATH}\")\n",
    "print(f\"Data raw: {DATA_RAW}\")\n",
    "print(f\"Data processed: {DATA_PROCESSED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc342038",
   "metadata": {},
   "source": [
    "## 2. Load HURDAT2 Data (2004–2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hurdat2():\n",
    "    \"\"\"Download HURDAT2 data from NOAA if not already cached.\"\"\"\n",
    "    url = \"https://www.nhc.noaa.gov/data/hurdat2/hurdat2.txt\"\n",
    "    output_file = DATA_RAW / \"hurdat2_raw.txt\"\n",
    "    \n",
    "    if output_file.exists():\n",
    "        print(f\"HURDAT2 data already exists at {output_file}\")\n",
    "        return output_file\n",
    "    \n",
    "    print(f\"Downloading HURDAT2 data from {url}...\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, output_file)\n",
    "        print(f\"✓ Successfully saved to {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_hurdat2(file_path):\n",
    "    \"\"\"\n",
    "    Parse HURDAT2 text file into a DataFrame.\n",
    "    Header lines contain storm info, data lines contain position/intensity.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    current_storm = None\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Header line (contains alphabetic character at start)\n",
    "            if line[0].isalpha():\n",
    "                parts = [p.strip() for p in line.split(',')]\n",
    "                if len(parts) >= 2:\n",
    "                    current_storm = {\n",
    "                        'id': parts[0],\n",
    "                        'name': parts[1],\n",
    "                        'num_records': int(parts[2])\n",
    "                    }\n",
    "            else:\n",
    "                # Data line (track point)\n",
    "                if current_storm:\n",
    "                    parts = [p.strip() for p in line.split(',')]\n",
    "                    if len(parts) >= 8:\n",
    "                        try:\n",
    "                            # Parse latitude (format: DDNH or DDDS)\n",
    "                            lat_str = parts[4]\n",
    "                            lat_val = float(lat_str[:-1])\n",
    "                            lat = lat_val if lat_str[-1] == 'N' else -lat_val\n",
    "                            \n",
    "                            # Parse longitude (format: DDDE or DDDW)\n",
    "                            lon_str = parts[5]\n",
    "                            lon_val = float(lon_str[:-1])\n",
    "                            lon = lon_val if lon_str[-1] == 'E' else -lon_val\n",
    "                            \n",
    "                            record = {\n",
    "                                'storm_id': current_storm['id'],\n",
    "                                'storm_name': current_storm['name'],\n",
    "                                'date': parts[0],\n",
    "                                'time': parts[1],\n",
    "                                'record_id': parts[2],\n",
    "                                'status': parts[3],\n",
    "                                'lat': lat,\n",
    "                                'lon': lon,\n",
    "                                'max_wind': int(parts[6]) if parts[6].lstrip('-').isdigit() else np.nan,\n",
    "                                'min_pressure': int(parts[7]) if parts[7].lstrip('-').isdigit() else np.nan,\n",
    "                            }\n",
    "                            records.append(record)\n",
    "                        except (ValueError, IndexError):\n",
    "                            continue\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    if not df.empty:\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')\n",
    "        df['year'] = df['date'].dt.year\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Download and parse data\n",
    "hurdat_file = download_hurdat2()\n",
    "if hurdat_file:\n",
    "    print(\"\\nParsing HURDAT2 data...\")\n",
    "    hurdat_df = parse_hurdat2(hurdat_file)\n",
    "    print(f\"✓ Total records: {len(hurdat_df):,}\")\n",
    "    print(f\"✓ Date range: {hurdat_df['date'].min()} to {hurdat_df['date'].max()}\")\n",
    "    print(f\"✓ Unique storms: {hurdat_df['storm_id'].nunique()}\")\n",
    "    print(f\"\\nFirst few records:\")\n",
    "    print(hurdat_df.head())\n",
    "else:\n",
    "    print(\"Failed to download HURDAT2 data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d51625b",
   "metadata": {},
   "source": [
    "## 3. Load Florida Boundary and Create GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3900541",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import geopandas as gpd\n",
    "    \n",
    "    # Load US states boundary from Natural Earth data (includes Florida)\n",
    "    # This uses the online source, which may take a moment\n",
    "    print(\"Loading US states boundary data...\")\n",
    "    us_states = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    us_states = us_states[us_states['iso_a3'] == 'USA']\n",
    "    \n",
    "    # For more detailed Florida boundary, try Natural Earth data\n",
    "    # If that fails, we'll create a bounding box approximation\n",
    "    try:\n",
    "        # Attempt to load higher resolution state boundaries\n",
    "        states = gpd.read_file('https://naciscdn.org/naturalearth/10m/admin_1_states_provinces.zip')\n",
    "        florida = states[(states['admin'] == 'United States of America') & \n",
    "                        (states['name'] == 'Florida')]\n",
    "        if not florida.empty:\n",
    "            print(\"✓ Loaded detailed Florida boundary from Natural Earth\")\n",
    "        else:\n",
    "            raise Exception(\"Florida not found in Natural Earth data\")\n",
    "    except:\n",
    "        # Fallback: Create Florida bounding polygon based on approximate coordinates\n",
    "        # Florida approximately spans: 24.5°N to 30.5°N, 80°W to 87.5°W\n",
    "        print(\"Creating Florida boundary polygon (approximate)...\")\n",
    "        florida_bounds = box(ymin=24.5, ymax=30.5, xmin=-87.5, xmax=-80.0)\n",
    "        florida = gpd.GeoDataFrame({'name': ['Florida (approximate)'], 'geometry': [florida_bounds]})\n",
    "    \n",
    "    florida = florida.to_crs(epsg=3857)  # Web Mercator projection\n",
    "    print(f\"✓ Florida boundary loaded\")\n",
    "    print(f\"  CRS: {florida.crs}\")\n",
    "    print(f\"  Bounds: {florida.total_bounds}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"geopandas or dependencies not installed. Installing...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call(['pip', 'install', 'geopandas', '-q'])\n",
    "    import geopandas as gpd\n",
    "    \n",
    "    # Try again\n",
    "    print(\"Loading US states boundary data...\")\n",
    "    us_states = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    florida_bounds = box(ymin=24.5, ymax=30.5, xmin=-87.5, xmax=-80.0)\n",
    "    florida = gpd.GeoDataFrame({'name': ['Florida (approximate)'], 'geometry': [florida_bounds]})\n",
    "    florida = florida.to_crs(epsg=3857)\n",
    "    print(\"✓ Florida boundary loaded (approximate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149dc077",
   "metadata": {},
   "source": [
    "## 4. Convert Storm Points to GeoDataFrame and Filter by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to 2004-2025 period first\n",
    "hurdat_2004_2025 = hurdat_df[(hurdat_df['year'] >= 2004) & (hurdat_df['year'] <= 2025)].copy()\n",
    "\n",
    "print(f\"Records in 2004-2025 period: {len(hurdat_2004_2025):,}\")\n",
    "print(f\"Storms in 2004-2025 period: {hurdat_2004_2025['storm_id'].nunique()}\")\n",
    "print(f\"Date range: {hurdat_2004_2025['date'].min()} to {hurdat_2004_2025['date'].max()}\")\n",
    "\n",
    "# Convert to GeoDataFrame with point geometries\n",
    "geometry = [Point(xy) for xy in zip(hurdat_2004_2025['lon'], hurdat_2004_2025['lat'])]\n",
    "hurdat_gdf = gpd.GeoDataFrame(hurdat_2004_2025, geometry=geometry, crs='EPSG:4326')\n",
    "\n",
    "# Convert to same projection as Florida for distance calculations\n",
    "hurdat_gdf = hurdat_gdf.to_crs(epsg=3857)\n",
    "\n",
    "print(f\"\\n✓ Created GeoDataFrame with {len(hurdat_gdf)} points\")\n",
    "print(f\"  CRS: {hurdat_gdf.crs}\")\n",
    "print(f\"\\nSample of converted data:\")\n",
    "print(hurdat_gdf[['date', 'storm_name', 'lat', 'lon', 'max_wind', 'geometry']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1103f68d",
   "metadata": {},
   "source": [
    "## 5. Filter Points Within 60 Nautical Miles of Florida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 60 nautical miles to meters\n",
    "# 1 nautical mile = 1852 meters\n",
    "BUFFER_DISTANCE_NM = 60\n",
    "BUFFER_DISTANCE_M = BUFFER_DISTANCE_NM * 1852\n",
    "\n",
    "print(f\"Creating {BUFFER_DISTANCE_NM} nautical mile buffer around Florida...\")\n",
    "print(f\"  {BUFFER_DISTANCE_NM} NM = {BUFFER_DISTANCE_M:,} meters\")\n",
    "\n",
    "# Create buffer around Florida\n",
    "florida_buffer = florida.copy()\n",
    "florida_buffer['geometry'] = florida_buffer.geometry.buffer(BUFFER_DISTANCE_M)\n",
    "\n",
    "# Find all hurricanes that intersect the buffered area\n",
    "hurdat_near_florida = hurdat_gdf[hurdat_gdf.geometry.within(florida_buffer.geometry.iloc[0])].copy()\n",
    "\n",
    "print(f\"\\n✓ Storms coming within {BUFFER_DISTANCE_NM} NM of Florida (2004-2025):\")\n",
    "print(f\"  Total points: {len(hurdat_near_florida):,}\")\n",
    "print(f\"  Unique storms: {hurdat_near_florida['storm_id'].nunique()}\")\n",
    "print(f\"  Year range: {hurdat_near_florida['year'].min()} to {hurdat_near_florida['year'].max()}\")\n",
    "\n",
    "# Alternative: Calculate minimum distance for each storm\n",
    "print(\"\\nCalculating closest approach to Florida for each storm...\")\n",
    "def min_distance_from_florida(group):\n",
    "    distances = group.geometry.distance(florida.geometry.iloc[0])\n",
    "    return distances.min() / 1852  # Convert back to nautical miles\n",
    "\n",
    "storm_distances = hurdat_gdf.groupby('storm_id').apply(min_distance_from_florida)\n",
    "storms_near_florida = storm_distances[storm_distances <= BUFFER_DISTANCE_NM].index.tolist()\n",
    "\n",
    "print(f\"Storms with closest point within {BUFFER_DISTANCE_NM} NM: {len(storms_near_florida)}\")\n",
    "\n",
    "# Get the detailed records for these storms\n",
    "hurdat_near_florida_alt = hurdat_gdf[hurdat_gdf['storm_id'].isin(storms_near_florida)].copy()\n",
    "\n",
    "print(f\"\\nDetailed records for {BUFFER_DISTANCE_NM} NM storms: {len(hurdat_near_florida_alt):,}\")\n",
    "print(f\"Unique storms: {hurdat_near_florida_alt['storm_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7fdf45",
   "metadata": {},
   "source": [
    "## 6. Summarize and Visualize Nearby Storm Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9636413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "print(\"=\"*80)\n",
    "print(f\"HURRICANES/TROPICAL STORMS WITHIN {BUFFER_DISTANCE_NM} NM OF FLORIDA\")\n",
    "print(f\"Years 2004-2025\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get summary for each storm\n",
    "storm_summary_list = []\n",
    "for storm_id in storms_near_florida:\n",
    "    storm_data = hurdat_near_florida_alt[hurdat_near_florida_alt['storm_id'] == storm_id]\n",
    "    storm_name = storm_data['storm_name'].iloc[0]\n",
    "    year = storm_data['year'].iloc[0]\n",
    "    \n",
    "    # Find minimum distance\n",
    "    min_dist_m = storm_data.geometry.distance(florida.geometry.iloc[0]).min()\n",
    "    min_dist_nm = min_dist_m / 1852\n",
    "    \n",
    "    # Get peak intensity\n",
    "    max_wind = storm_data['max_wind'].max()\n",
    "    min_pressure = storm_data['min_pressure'].min()\n",
    "    \n",
    "    # Get date range\n",
    "    start_date = storm_data['date'].min()\n",
    "    end_date = storm_data['date'].max()\n",
    "    \n",
    "    storm_summary_list.append({\n",
    "        'Year': year,\n",
    "        'Storm ID': storm_id,\n",
    "        'Storm Name': storm_name,\n",
    "        'Closest Distance (NM)': round(min_dist_nm, 1),\n",
    "        'Max Wind Speed (kt)': int(max_wind) if pd.notna(max_wind) else 'N/A',\n",
    "        'Min Pressure (mb)': int(min_pressure) if pd.notna(min_pressure) else 'N/A',\n",
    "        'Start Date': start_date.strftime('%Y-%m-%d'),\n",
    "        'End Date': end_date.strftime('%Y-%m-%d')\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(storm_summary_list).sort_values('Year')\n",
    "\n",
    "print(\"\\n\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "summary_csv = DATA_PROCESSED / f\"florida_storms_{BUFFER_DISTANCE_NM}nm_2004_2025.csv\"\n",
    "summary_df.to_csv(summary_csv, index=False)\n",
    "print(f\"\\n✓ Summary saved to: {summary_csv}\")\n",
    "\n",
    "# Save detailed GeoJSON\n",
    "geojson_file = DATA_PROCESSED / f\"florida_storms_{BUFFER_DISTANCE_NM}nm_2004_2025.geojson\"\n",
    "hurdat_near_florida_alt[['date', 'storm_id', 'storm_name', 'year', 'lat', 'lon', 'max_wind', 'min_pressure', 'geometry']].to_file(geojson_file, driver='GeoJSON')\n",
    "print(f\"✓ GeoJSON saved to: {geojson_file}\")\n",
    "\n",
    "# Summary statistics by year\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STORM COUNT BY YEAR\")\n",
    "print(\"=\"*80)\n",
    "yearly_summary = summary_df.groupby('Year').size()\n",
    "print(yearly_summary)\n",
    "\n",
    "print(f\"\\nTotal storms affecting Florida (2004-2025): {len(summary_df)}\")\n",
    "print(f\"Average storms per year: {len(summary_df) / 22:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3015c7d3",
   "metadata": {},
   "source": [
    "## 7. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "# Create a map visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Plot 1: Storm tracks and Florida boundary with buffer\n",
    "ax1.set_title(f'Hurricane Tracks within {BUFFER_DISTANCE_NM} NM of Florida\\n(2004-2025)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot Florida (convert back to lat/lon for visualization)\n",
    "florida_plot = florida.to_crs('EPSG:4326')\n",
    "florida_plot.plot(ax=ax1, alpha=0.3, edgecolor='green', facecolor='lightgreen', label='Florida')\n",
    "\n",
    "# Plot 60 NM buffer (approximate circle on map)\n",
    "florida_center_lon = florida_plot.geometry.centroid.x.iloc[0]\n",
    "florida_center_lat = florida_plot.geometry.centroid.y.iloc[0]\n",
    "# Approximate circle (in degrees, rough conversion)\n",
    "buffer_deg = BUFFER_DISTANCE_NM / 69  # 1 degree ≈ 69 miles / ≈ 59 NM\n",
    "circle = Circle((florida_center_lon, florida_center_lat), buffer_deg, \n",
    "                color='blue', fill=False, linestyle='--', linewidth=2, label=f'{BUFFER_DISTANCE_NM} NM buffer')\n",
    "ax1.add_patch(circle)\n",
    "\n",
    "# Plot hurricane points and color by wind speed\n",
    "hurdat_plot = hurdat_near_florida_alt.to_crs('EPSG:4326')\n",
    "scatter = ax1.scatter(hurdat_plot.geometry.x, hurdat_plot.geometry.y, \n",
    "                     c=hurdat_plot['max_wind'], cmap='YlOrRd', s=20, alpha=0.6, \n",
    "                     vmin=35, vmax=150)\n",
    "\n",
    "ax1.set_xlabel('Longitude', fontsize=11)\n",
    "ax1.set_ylabel('Latitude', fontsize=11)\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "cbar1 = plt.colorbar(scatter, ax=ax1)\n",
    "cbar1.set_label('Wind Speed (knots)', fontsize=10)\n",
    "\n",
    "# Plot 2: Storm count by year\n",
    "yearly_count = summary_df.groupby('Year').size()\n",
    "ax2.bar(yearly_count.index, yearly_count.values, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax2.set_title('Tropical Cyclones Affecting Florida Area\\nby Year (2004-2025)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Year', fontsize=11)\n",
    "ax2.set_ylabel('Number of Storms', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "ax2.set_xlim(2003.5, 2025.5)\n",
    "\n",
    "# Add average line\n",
    "avg_storms = len(summary_df) / 22\n",
    "ax2.axhline(y=avg_storms, color='red', linestyle='--', linewidth=2, label=f'Average: {avg_storms:.1f}')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_path = Path(__file__).parent.parent / \"results\" / \"figures\" / f\"florida_storms_{BUFFER_DISTANCE_NM}nm_analysis.png\"\n",
    "fig_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ Map saved to: {fig_path}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
